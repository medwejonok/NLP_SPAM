{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_spam.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>make sure alex knows his birthday is over in f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>a resume for john lavorato thanks vince i will...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>plzz visit my website moviesgodml to get all m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>urgent your mobile number has been awarded wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>overview of hr associates analyst project per ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16273</th>\n",
       "      <td>spam</td>\n",
       "      <td>if you are interested in binary options tradin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16274</th>\n",
       "      <td>spam</td>\n",
       "      <td>dirty pictureblyk on aircel thanks you for bei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16275</th>\n",
       "      <td>ham</td>\n",
       "      <td>or you could do this g on mon 1635465 sep 1635...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16276</th>\n",
       "      <td>ham</td>\n",
       "      <td>insta reels par 80 à¤—à¤‚à¤¦ bhara pada hai ðŸ‘€ kuch b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16277</th>\n",
       "      <td>ham</td>\n",
       "      <td>alex s paper comments 1 in the sentence betwee...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16278 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      text_type                                               text\n",
       "0           ham  make sure alex knows his birthday is over in f...\n",
       "1           ham  a resume for john lavorato thanks vince i will...\n",
       "2          spam  plzz visit my website moviesgodml to get all m...\n",
       "3          spam  urgent your mobile number has been awarded wit...\n",
       "4           ham  overview of hr associates analyst project per ...\n",
       "...         ...                                                ...\n",
       "16273      spam  if you are interested in binary options tradin...\n",
       "16274      spam  dirty pictureblyk on aircel thanks you for bei...\n",
       "16275       ham  or you could do this g on mon 1635465 sep 1635...\n",
       "16276       ham  insta reels par 80 à¤—à¤‚à¤¦ bhara pada hai ðŸ‘€ kuch b...\n",
       "16277       ham  alex s paper comments 1 in the sentence betwee...\n",
       "\n",
       "[16278 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4, 2))\n",
    "sns.heatmap(df.isnull(), yticklabels=False, cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIPELINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "   <img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/1af/e66/5f0/1afe665f038a06b3cf7eaef4e3c8e928.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) LowCase, Tokenize, Stop-words, Lem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 1) LowerCase "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>make sure alex knows his birthday is over in f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>a resume for john lavorato thanks vince i will...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>plzz visit my website moviesgodml to get all m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>urgent your mobile number has been awarded wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>overview of hr associates analyst project per ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16273</th>\n",
       "      <td>spam</td>\n",
       "      <td>if you are interested in binary options tradin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16274</th>\n",
       "      <td>spam</td>\n",
       "      <td>dirty pictureblyk on aircel thanks you for bei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16275</th>\n",
       "      <td>ham</td>\n",
       "      <td>or you could do this g on mon 1635465 sep 1635...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16276</th>\n",
       "      <td>ham</td>\n",
       "      <td>insta reels par 80 à¤—à¤‚à¤¦ bhara pada hai ðŸ‘€ kuch b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16277</th>\n",
       "      <td>ham</td>\n",
       "      <td>alex s paper comments 1 in the sentence betwee...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16278 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      text_type                                               text\n",
       "0           ham  make sure alex knows his birthday is over in f...\n",
       "1           ham  a resume for john lavorato thanks vince i will...\n",
       "2          spam  plzz visit my website moviesgodml to get all m...\n",
       "3          spam  urgent your mobile number has been awarded wit...\n",
       "4           ham  overview of hr associates analyst project per ...\n",
       "...         ...                                                ...\n",
       "16273      spam  if you are interested in binary options tradin...\n",
       "16274      spam  dirty pictureblyk on aircel thanks you for bei...\n",
       "16275       ham  or you could do this g on mon 1635465 sep 1635...\n",
       "16276       ham  insta reels par 80 à¤—à¤‚à¤¦ bhara pada hai ðŸ‘€ kuch b...\n",
       "16277       ham  alex s paper comments 1 in the sentence betwee...\n",
       "\n",
       "[16278 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 2) Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ataka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "def tokenize(text):\n",
    "    \"\"\"Tokenizes a string of text and returns a list of tokens.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text to tokenize.\n",
    "\n",
    "    Returns:\n",
    "        tokens (list): A list of tokens.\n",
    "    \"\"\"\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    return [w for w in tokens if w.isalpha()]\n",
    "\n",
    "# Assuming df is your dataframe and it has a 'text' column\n",
    "df['text_tokenize'] = df['text'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_type</th>\n",
       "      <th>text</th>\n",
       "      <th>text_tokenize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>make sure alex knows his birthday is over in f...</td>\n",
       "      <td>[make, sure, alex, knows, his, birthday, is, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>a resume for john lavorato thanks vince i will...</td>\n",
       "      <td>[a, resume, for, john, lavorato, thanks, vince...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>plzz visit my website moviesgodml to get all m...</td>\n",
       "      <td>[plzz, visit, my, website, moviesgodml, to, ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>urgent your mobile number has been awarded wit...</td>\n",
       "      <td>[urgent, your, mobile, number, has, been, awar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>overview of hr associates analyst project per ...</td>\n",
       "      <td>[overview, of, hr, associates, analyst, projec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16273</th>\n",
       "      <td>spam</td>\n",
       "      <td>if you are interested in binary options tradin...</td>\n",
       "      <td>[if, you, are, interested, in, binary, options...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16274</th>\n",
       "      <td>spam</td>\n",
       "      <td>dirty pictureblyk on aircel thanks you for bei...</td>\n",
       "      <td>[dirty, pictureblyk, on, aircel, thanks, you, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16275</th>\n",
       "      <td>ham</td>\n",
       "      <td>or you could do this g on mon 1635465 sep 1635...</td>\n",
       "      <td>[or, you, could, do, this, g, on, mon, sep, da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16276</th>\n",
       "      <td>ham</td>\n",
       "      <td>insta reels par 80 à¤—à¤‚à¤¦ bhara pada hai ðŸ‘€ kuch b...</td>\n",
       "      <td>[insta, reels, par, bhara, pada, hai, kuch, bh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16277</th>\n",
       "      <td>ham</td>\n",
       "      <td>alex s paper comments 1 in the sentence betwee...</td>\n",
       "      <td>[alex, s, paper, comments, in, the, sentence, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16278 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      text_type                                               text  \\\n",
       "0           ham  make sure alex knows his birthday is over in f...   \n",
       "1           ham  a resume for john lavorato thanks vince i will...   \n",
       "2          spam  plzz visit my website moviesgodml to get all m...   \n",
       "3          spam  urgent your mobile number has been awarded wit...   \n",
       "4           ham  overview of hr associates analyst project per ...   \n",
       "...         ...                                                ...   \n",
       "16273      spam  if you are interested in binary options tradin...   \n",
       "16274      spam  dirty pictureblyk on aircel thanks you for bei...   \n",
       "16275       ham  or you could do this g on mon 1635465 sep 1635...   \n",
       "16276       ham  insta reels par 80 à¤—à¤‚à¤¦ bhara pada hai ðŸ‘€ kuch b...   \n",
       "16277       ham  alex s paper comments 1 in the sentence betwee...   \n",
       "\n",
       "                                           text_tokenize  \n",
       "0      [make, sure, alex, knows, his, birthday, is, o...  \n",
       "1      [a, resume, for, john, lavorato, thanks, vince...  \n",
       "2      [plzz, visit, my, website, moviesgodml, to, ge...  \n",
       "3      [urgent, your, mobile, number, has, been, awar...  \n",
       "4      [overview, of, hr, associates, analyst, projec...  \n",
       "...                                                  ...  \n",
       "16273  [if, you, are, interested, in, binary, options...  \n",
       "16274  [dirty, pictureblyk, on, aircel, thanks, you, ...  \n",
       "16275  [or, you, could, do, this, g, on, mon, sep, da...  \n",
       "16276  [insta, reels, par, bhara, pada, hai, kuch, bh...  \n",
       "16277  [alex, s, paper, comments, in, the, sentence, ...  \n",
       "\n",
       "[16278 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 3) Stop-words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ataka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "df['text_no_stop_words'] = df['text_tokenize'].apply(lambda x: [word for word in x if word.lower() not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_type</th>\n",
       "      <th>text</th>\n",
       "      <th>text_tokenize</th>\n",
       "      <th>text_no_stop_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>make sure alex knows his birthday is over in f...</td>\n",
       "      <td>[make, sure, alex, knows, his, birthday, is, o...</td>\n",
       "      <td>[make, sure, alex, knows, birthday, fifteen, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>a resume for john lavorato thanks vince i will...</td>\n",
       "      <td>[a, resume, for, john, lavorato, thanks, vince...</td>\n",
       "      <td>[resume, john, lavorato, thanks, vince, get, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>plzz visit my website moviesgodml to get all m...</td>\n",
       "      <td>[plzz, visit, my, website, moviesgodml, to, ge...</td>\n",
       "      <td>[plzz, visit, website, moviesgodml, get, movie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>urgent your mobile number has been awarded wit...</td>\n",
       "      <td>[urgent, your, mobile, number, has, been, awar...</td>\n",
       "      <td>[urgent, mobile, number, awarded, prize, guara...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>overview of hr associates analyst project per ...</td>\n",
       "      <td>[overview, of, hr, associates, analyst, projec...</td>\n",
       "      <td>[overview, hr, associates, analyst, project, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16273</th>\n",
       "      <td>spam</td>\n",
       "      <td>if you are interested in binary options tradin...</td>\n",
       "      <td>[if, you, are, interested, in, binary, options...</td>\n",
       "      <td>[interested, binary, options, trading, may, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16274</th>\n",
       "      <td>spam</td>\n",
       "      <td>dirty pictureblyk on aircel thanks you for bei...</td>\n",
       "      <td>[dirty, pictureblyk, on, aircel, thanks, you, ...</td>\n",
       "      <td>[dirty, pictureblyk, aircel, thanks, valued, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16275</th>\n",
       "      <td>ham</td>\n",
       "      <td>or you could do this g on mon 1635465 sep 1635...</td>\n",
       "      <td>[or, you, could, do, this, g, on, mon, sep, da...</td>\n",
       "      <td>[could, g, mon, sep, david, rees, wrote, mon, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16276</th>\n",
       "      <td>ham</td>\n",
       "      <td>insta reels par 80 à¤—à¤‚à¤¦ bhara pada hai ðŸ‘€ kuch b...</td>\n",
       "      <td>[insta, reels, par, bhara, pada, hai, kuch, bh...</td>\n",
       "      <td>[insta, reels, par, bhara, pada, hai, kuch, bh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16277</th>\n",
       "      <td>ham</td>\n",
       "      <td>alex s paper comments 1 in the sentence betwee...</td>\n",
       "      <td>[alex, s, paper, comments, in, the, sentence, ...</td>\n",
       "      <td>[alex, paper, comments, sentence, eqn, eqn, th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16278 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      text_type                                               text  \\\n",
       "0           ham  make sure alex knows his birthday is over in f...   \n",
       "1           ham  a resume for john lavorato thanks vince i will...   \n",
       "2          spam  plzz visit my website moviesgodml to get all m...   \n",
       "3          spam  urgent your mobile number has been awarded wit...   \n",
       "4           ham  overview of hr associates analyst project per ...   \n",
       "...         ...                                                ...   \n",
       "16273      spam  if you are interested in binary options tradin...   \n",
       "16274      spam  dirty pictureblyk on aircel thanks you for bei...   \n",
       "16275       ham  or you could do this g on mon 1635465 sep 1635...   \n",
       "16276       ham  insta reels par 80 à¤—à¤‚à¤¦ bhara pada hai ðŸ‘€ kuch b...   \n",
       "16277       ham  alex s paper comments 1 in the sentence betwee...   \n",
       "\n",
       "                                           text_tokenize  \\\n",
       "0      [make, sure, alex, knows, his, birthday, is, o...   \n",
       "1      [a, resume, for, john, lavorato, thanks, vince...   \n",
       "2      [plzz, visit, my, website, moviesgodml, to, ge...   \n",
       "3      [urgent, your, mobile, number, has, been, awar...   \n",
       "4      [overview, of, hr, associates, analyst, projec...   \n",
       "...                                                  ...   \n",
       "16273  [if, you, are, interested, in, binary, options...   \n",
       "16274  [dirty, pictureblyk, on, aircel, thanks, you, ...   \n",
       "16275  [or, you, could, do, this, g, on, mon, sep, da...   \n",
       "16276  [insta, reels, par, bhara, pada, hai, kuch, bh...   \n",
       "16277  [alex, s, paper, comments, in, the, sentence, ...   \n",
       "\n",
       "                                      text_no_stop_words  \n",
       "0      [make, sure, alex, knows, birthday, fifteen, m...  \n",
       "1      [resume, john, lavorato, thanks, vince, get, m...  \n",
       "2      [plzz, visit, website, moviesgodml, get, movie...  \n",
       "3      [urgent, mobile, number, awarded, prize, guara...  \n",
       "4      [overview, hr, associates, analyst, project, p...  \n",
       "...                                                  ...  \n",
       "16273  [interested, binary, options, trading, may, co...  \n",
       "16274  [dirty, pictureblyk, aircel, thanks, valued, m...  \n",
       "16275  [could, g, mon, sep, david, rees, wrote, mon, ...  \n",
       "16276  [insta, reels, par, bhara, pada, hai, kuch, bh...  \n",
       "16277  [alex, paper, comments, sentence, eqn, eqn, th...  \n",
       "\n",
       "[16278 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 4) Lem\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\ataka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ataka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def lemmatize_word(word):\n",
    "    \"\"\"Lemmatize a word using WordNetLemmatizer.\n",
    "\n",
    "    Args:\n",
    "        word (str): The word to lemmatize.\n",
    "\n",
    "    Returns:\n",
    "        str: The lemmatized word.\n",
    "    \"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    pos_tag = get_wordnet_pos(word)\n",
    "    lemma = lemmatizer.lemmatize(word, pos=pos_tag)\n",
    "    return lemma\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to WordNet POS tag.\n",
    "\n",
    "    Args:\n",
    "        word (str): The word to get the POS tag for.\n",
    "\n",
    "    Returns:\n",
    "        str: The WordNet POS tag.\n",
    "    \"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "df['text_lemmatized'] = df['text_no_stop_words'].apply(lambda x: [lemmatize_word(word) for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_type</th>\n",
       "      <th>text</th>\n",
       "      <th>text_tokenize</th>\n",
       "      <th>text_no_stop_words</th>\n",
       "      <th>text_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>make sure alex knows his birthday is over in f...</td>\n",
       "      <td>[make, sure, alex, knows, his, birthday, is, o...</td>\n",
       "      <td>[make, sure, alex, knows, birthday, fifteen, m...</td>\n",
       "      <td>[make, sure, alex, know, birthday, fifteen, mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>a resume for john lavorato thanks vince i will...</td>\n",
       "      <td>[a, resume, for, john, lavorato, thanks, vince...</td>\n",
       "      <td>[resume, john, lavorato, thanks, vince, get, m...</td>\n",
       "      <td>[resume, john, lavorato, thanks, vince, get, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>plzz visit my website moviesgodml to get all m...</td>\n",
       "      <td>[plzz, visit, my, website, moviesgodml, to, ge...</td>\n",
       "      <td>[plzz, visit, website, moviesgodml, get, movie...</td>\n",
       "      <td>[plzz, visit, website, moviesgodml, get, movie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>urgent your mobile number has been awarded wit...</td>\n",
       "      <td>[urgent, your, mobile, number, has, been, awar...</td>\n",
       "      <td>[urgent, mobile, number, awarded, prize, guara...</td>\n",
       "      <td>[urgent, mobile, number, award, prize, guarant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>overview of hr associates analyst project per ...</td>\n",
       "      <td>[overview, of, hr, associates, analyst, projec...</td>\n",
       "      <td>[overview, hr, associates, analyst, project, p...</td>\n",
       "      <td>[overview, hr, associate, analyst, project, pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16273</th>\n",
       "      <td>spam</td>\n",
       "      <td>if you are interested in binary options tradin...</td>\n",
       "      <td>[if, you, are, interested, in, binary, options...</td>\n",
       "      <td>[interested, binary, options, trading, may, co...</td>\n",
       "      <td>[interested, binary, option, trading, may, con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16274</th>\n",
       "      <td>spam</td>\n",
       "      <td>dirty pictureblyk on aircel thanks you for bei...</td>\n",
       "      <td>[dirty, pictureblyk, on, aircel, thanks, you, ...</td>\n",
       "      <td>[dirty, pictureblyk, aircel, thanks, valued, m...</td>\n",
       "      <td>[dirty, pictureblyk, aircel, thanks, value, me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16275</th>\n",
       "      <td>ham</td>\n",
       "      <td>or you could do this g on mon 1635465 sep 1635...</td>\n",
       "      <td>[or, you, could, do, this, g, on, mon, sep, da...</td>\n",
       "      <td>[could, g, mon, sep, david, rees, wrote, mon, ...</td>\n",
       "      <td>[could, g, mon, sep, david, rees, write, mon, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16276</th>\n",
       "      <td>ham</td>\n",
       "      <td>insta reels par 80 à¤—à¤‚à¤¦ bhara pada hai ðŸ‘€ kuch b...</td>\n",
       "      <td>[insta, reels, par, bhara, pada, hai, kuch, bh...</td>\n",
       "      <td>[insta, reels, par, bhara, pada, hai, kuch, bh...</td>\n",
       "      <td>[insta, reel, par, bhara, pada, hai, kuch, bhi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16277</th>\n",
       "      <td>ham</td>\n",
       "      <td>alex s paper comments 1 in the sentence betwee...</td>\n",
       "      <td>[alex, s, paper, comments, in, the, sentence, ...</td>\n",
       "      <td>[alex, paper, comments, sentence, eqn, eqn, th...</td>\n",
       "      <td>[alex, paper, comment, sentence, eqn, eqn, thi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16278 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      text_type                                               text  \\\n",
       "0           ham  make sure alex knows his birthday is over in f...   \n",
       "1           ham  a resume for john lavorato thanks vince i will...   \n",
       "2          spam  plzz visit my website moviesgodml to get all m...   \n",
       "3          spam  urgent your mobile number has been awarded wit...   \n",
       "4           ham  overview of hr associates analyst project per ...   \n",
       "...         ...                                                ...   \n",
       "16273      spam  if you are interested in binary options tradin...   \n",
       "16274      spam  dirty pictureblyk on aircel thanks you for bei...   \n",
       "16275       ham  or you could do this g on mon 1635465 sep 1635...   \n",
       "16276       ham  insta reels par 80 à¤—à¤‚à¤¦ bhara pada hai ðŸ‘€ kuch b...   \n",
       "16277       ham  alex s paper comments 1 in the sentence betwee...   \n",
       "\n",
       "                                           text_tokenize  \\\n",
       "0      [make, sure, alex, knows, his, birthday, is, o...   \n",
       "1      [a, resume, for, john, lavorato, thanks, vince...   \n",
       "2      [plzz, visit, my, website, moviesgodml, to, ge...   \n",
       "3      [urgent, your, mobile, number, has, been, awar...   \n",
       "4      [overview, of, hr, associates, analyst, projec...   \n",
       "...                                                  ...   \n",
       "16273  [if, you, are, interested, in, binary, options...   \n",
       "16274  [dirty, pictureblyk, on, aircel, thanks, you, ...   \n",
       "16275  [or, you, could, do, this, g, on, mon, sep, da...   \n",
       "16276  [insta, reels, par, bhara, pada, hai, kuch, bh...   \n",
       "16277  [alex, s, paper, comments, in, the, sentence, ...   \n",
       "\n",
       "                                      text_no_stop_words  \\\n",
       "0      [make, sure, alex, knows, birthday, fifteen, m...   \n",
       "1      [resume, john, lavorato, thanks, vince, get, m...   \n",
       "2      [plzz, visit, website, moviesgodml, get, movie...   \n",
       "3      [urgent, mobile, number, awarded, prize, guara...   \n",
       "4      [overview, hr, associates, analyst, project, p...   \n",
       "...                                                  ...   \n",
       "16273  [interested, binary, options, trading, may, co...   \n",
       "16274  [dirty, pictureblyk, aircel, thanks, valued, m...   \n",
       "16275  [could, g, mon, sep, david, rees, wrote, mon, ...   \n",
       "16276  [insta, reels, par, bhara, pada, hai, kuch, bh...   \n",
       "16277  [alex, paper, comments, sentence, eqn, eqn, th...   \n",
       "\n",
       "                                         text_lemmatized  \n",
       "0      [make, sure, alex, know, birthday, fifteen, mi...  \n",
       "1      [resume, john, lavorato, thanks, vince, get, m...  \n",
       "2      [plzz, visit, website, moviesgodml, get, movie...  \n",
       "3      [urgent, mobile, number, award, prize, guarant...  \n",
       "4      [overview, hr, associate, analyst, project, pe...  \n",
       "...                                                  ...  \n",
       "16273  [interested, binary, option, trading, may, con...  \n",
       "16274  [dirty, pictureblyk, aircel, thanks, value, me...  \n",
       "16275  [could, g, mon, sep, david, rees, write, mon, ...  \n",
       "16276  [insta, reel, par, bhara, pada, hai, kuch, bhi...  \n",
       "16277  [alex, paper, comment, sentence, eqn, eqn, thi...  \n",
       "\n",
       "[16278 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ð­Ð¼Ð±ÐµÐ´Ð¸Ð½Ð³Ð¸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "df['text_tfidf'] = df['text_lemmatized'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "tf_idf_emb = vectorizer.fit_transform(df['text_tfidf'])\n",
    "df['text_tfidf'] = tf_idf_emb.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_type</th>\n",
       "      <th>text</th>\n",
       "      <th>text_tokenize</th>\n",
       "      <th>text_no_stop_words</th>\n",
       "      <th>text_lemmatized</th>\n",
       "      <th>text_tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>make sure alex knows his birthday is over in f...</td>\n",
       "      <td>[make, sure, alex, knows, his, birthday, is, o...</td>\n",
       "      <td>[make, sure, alex, knows, birthday, fifteen, m...</td>\n",
       "      <td>[make, sure, alex, know, birthday, fifteen, mi...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>a resume for john lavorato thanks vince i will...</td>\n",
       "      <td>[a, resume, for, john, lavorato, thanks, vince...</td>\n",
       "      <td>[resume, john, lavorato, thanks, vince, get, m...</td>\n",
       "      <td>[resume, john, lavorato, thanks, vince, get, m...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>plzz visit my website moviesgodml to get all m...</td>\n",
       "      <td>[plzz, visit, my, website, moviesgodml, to, ge...</td>\n",
       "      <td>[plzz, visit, website, moviesgodml, get, movie...</td>\n",
       "      <td>[plzz, visit, website, moviesgodml, get, movie...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>urgent your mobile number has been awarded wit...</td>\n",
       "      <td>[urgent, your, mobile, number, has, been, awar...</td>\n",
       "      <td>[urgent, mobile, number, awarded, prize, guara...</td>\n",
       "      <td>[urgent, mobile, number, award, prize, guarant...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>overview of hr associates analyst project per ...</td>\n",
       "      <td>[overview, of, hr, associates, analyst, projec...</td>\n",
       "      <td>[overview, hr, associates, analyst, project, p...</td>\n",
       "      <td>[overview, hr, associate, analyst, project, pe...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16273</th>\n",
       "      <td>spam</td>\n",
       "      <td>if you are interested in binary options tradin...</td>\n",
       "      <td>[if, you, are, interested, in, binary, options...</td>\n",
       "      <td>[interested, binary, options, trading, may, co...</td>\n",
       "      <td>[interested, binary, option, trading, may, con...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16274</th>\n",
       "      <td>spam</td>\n",
       "      <td>dirty pictureblyk on aircel thanks you for bei...</td>\n",
       "      <td>[dirty, pictureblyk, on, aircel, thanks, you, ...</td>\n",
       "      <td>[dirty, pictureblyk, aircel, thanks, valued, m...</td>\n",
       "      <td>[dirty, pictureblyk, aircel, thanks, value, me...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16275</th>\n",
       "      <td>ham</td>\n",
       "      <td>or you could do this g on mon 1635465 sep 1635...</td>\n",
       "      <td>[or, you, could, do, this, g, on, mon, sep, da...</td>\n",
       "      <td>[could, g, mon, sep, david, rees, wrote, mon, ...</td>\n",
       "      <td>[could, g, mon, sep, david, rees, write, mon, ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16276</th>\n",
       "      <td>ham</td>\n",
       "      <td>insta reels par 80 à¤—à¤‚à¤¦ bhara pada hai ðŸ‘€ kuch b...</td>\n",
       "      <td>[insta, reels, par, bhara, pada, hai, kuch, bh...</td>\n",
       "      <td>[insta, reels, par, bhara, pada, hai, kuch, bh...</td>\n",
       "      <td>[insta, reel, par, bhara, pada, hai, kuch, bhi...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16277</th>\n",
       "      <td>ham</td>\n",
       "      <td>alex s paper comments 1 in the sentence betwee...</td>\n",
       "      <td>[alex, s, paper, comments, in, the, sentence, ...</td>\n",
       "      <td>[alex, paper, comments, sentence, eqn, eqn, th...</td>\n",
       "      <td>[alex, paper, comment, sentence, eqn, eqn, thi...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16278 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      text_type                                               text  \\\n",
       "0           ham  make sure alex knows his birthday is over in f...   \n",
       "1           ham  a resume for john lavorato thanks vince i will...   \n",
       "2          spam  plzz visit my website moviesgodml to get all m...   \n",
       "3          spam  urgent your mobile number has been awarded wit...   \n",
       "4           ham  overview of hr associates analyst project per ...   \n",
       "...         ...                                                ...   \n",
       "16273      spam  if you are interested in binary options tradin...   \n",
       "16274      spam  dirty pictureblyk on aircel thanks you for bei...   \n",
       "16275       ham  or you could do this g on mon 1635465 sep 1635...   \n",
       "16276       ham  insta reels par 80 à¤—à¤‚à¤¦ bhara pada hai ðŸ‘€ kuch b...   \n",
       "16277       ham  alex s paper comments 1 in the sentence betwee...   \n",
       "\n",
       "                                           text_tokenize  \\\n",
       "0      [make, sure, alex, knows, his, birthday, is, o...   \n",
       "1      [a, resume, for, john, lavorato, thanks, vince...   \n",
       "2      [plzz, visit, my, website, moviesgodml, to, ge...   \n",
       "3      [urgent, your, mobile, number, has, been, awar...   \n",
       "4      [overview, of, hr, associates, analyst, projec...   \n",
       "...                                                  ...   \n",
       "16273  [if, you, are, interested, in, binary, options...   \n",
       "16274  [dirty, pictureblyk, on, aircel, thanks, you, ...   \n",
       "16275  [or, you, could, do, this, g, on, mon, sep, da...   \n",
       "16276  [insta, reels, par, bhara, pada, hai, kuch, bh...   \n",
       "16277  [alex, s, paper, comments, in, the, sentence, ...   \n",
       "\n",
       "                                      text_no_stop_words  \\\n",
       "0      [make, sure, alex, knows, birthday, fifteen, m...   \n",
       "1      [resume, john, lavorato, thanks, vince, get, m...   \n",
       "2      [plzz, visit, website, moviesgodml, get, movie...   \n",
       "3      [urgent, mobile, number, awarded, prize, guara...   \n",
       "4      [overview, hr, associates, analyst, project, p...   \n",
       "...                                                  ...   \n",
       "16273  [interested, binary, options, trading, may, co...   \n",
       "16274  [dirty, pictureblyk, aircel, thanks, valued, m...   \n",
       "16275  [could, g, mon, sep, david, rees, wrote, mon, ...   \n",
       "16276  [insta, reels, par, bhara, pada, hai, kuch, bh...   \n",
       "16277  [alex, paper, comments, sentence, eqn, eqn, th...   \n",
       "\n",
       "                                         text_lemmatized  text_tfidf  \n",
       "0      [make, sure, alex, know, birthday, fifteen, mi...         0.0  \n",
       "1      [resume, john, lavorato, thanks, vince, get, m...         0.0  \n",
       "2      [plzz, visit, website, moviesgodml, get, movie...         0.0  \n",
       "3      [urgent, mobile, number, award, prize, guarant...         0.0  \n",
       "4      [overview, hr, associate, analyst, project, pe...         0.0  \n",
       "...                                                  ...         ...  \n",
       "16273  [interested, binary, option, trading, may, con...         0.0  \n",
       "16274  [dirty, pictureblyk, aircel, thanks, value, me...         0.0  \n",
       "16275  [could, g, mon, sep, david, rees, write, mon, ...         0.0  \n",
       "16276  [insta, reel, par, bhara, pada, hai, kuch, bhi...         0.0  \n",
       "16277  [alex, paper, comment, sentence, eqn, eqn, thi...         0.0  \n",
       "\n",
       "[16278 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 2) BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ataka\\anaconda3\\envs\\ml\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def bert_embedding(text):\n",
    "    \"\"\"Compute the BERT embedding for a given text.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text to compute the embedding for.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The BERT embedding for the text.\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(text, return_tensors='pt')\n",
    "    outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state[:, 0, :]\n",
    "\n",
    "bert_embedding('holla amigo how are you')\n",
    "\n",
    "res = df['text_lemmatized'][:10].apply(lambda x: bert_embedding(' '.join(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [[tensor(0.0705, grad_fn=<UnbindBackward0>), t...\n",
       "1    [[tensor(-0.6561, grad_fn=<UnbindBackward0>), ...\n",
       "2    [[tensor(0.0743, grad_fn=<UnbindBackward0>), t...\n",
       "3    [[tensor(-0.5720, grad_fn=<UnbindBackward0>), ...\n",
       "4    [[tensor(-0.5436, grad_fn=<UnbindBackward0>), ...\n",
       "5    [[tensor(-0.0433, grad_fn=<UnbindBackward0>), ...\n",
       "6    [[tensor(-0.0238, grad_fn=<UnbindBackward0>), ...\n",
       "7    [[tensor(-0.3113, grad_fn=<UnbindBackward0>), ...\n",
       "8    [[tensor(-0.2870, grad_fn=<UnbindBackward0>), ...\n",
       "9    [[tensor(-0.1735, grad_fn=<UnbindBackward0>), ...\n",
       "Name: text_lemmatized, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased').cuda()  # Move the model to GPU\n",
    "\n",
    "def bert_embedding(text):\n",
    "    \"\"\"Compute the BERT embedding for a given text.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text to compute the embedding for.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The BERT embedding for the text.\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(text, return_tensors='pt').to('cuda')  # Move the data to GPU\n",
    "    outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state[:, 0, :].to('cpu')  # Move the result back to CPU\n",
    "\n",
    "bert_embedding('holla amigo how are you').to('cpu')  # Move the result back to CPU\n",
    "\n",
    "# Assuming df is a pandas DataFrame and 'text_lemmatized' is a column in the DataFrame\n",
    "res = df['text_lemmatized'][:100].apply(lambda x: bert_embedding(' '.join(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3,4,5,6,7,8,9, 10, 11]\n",
    "a[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [[tensor(0.0705, grad_fn=<UnbindBackward0>), t...\n",
       "1     [[tensor(-0.6561, grad_fn=<UnbindBackward0>), ...\n",
       "2     [[tensor(0.0743, grad_fn=<UnbindBackward0>), t...\n",
       "3     [[tensor(-0.5720, grad_fn=<UnbindBackward0>), ...\n",
       "4     [[tensor(-0.5436, grad_fn=<UnbindBackward0>), ...\n",
       "                            ...                        \n",
       "95    [[tensor(-0.0197, grad_fn=<UnbindBackward0>), ...\n",
       "96    [[tensor(-0.2313, grad_fn=<UnbindBackward0>), ...\n",
       "97    [[tensor(-0.3809, grad_fn=<UnbindBackward0>), ...\n",
       "98    [[tensor(-0.2824, grad_fn=<UnbindBackward0>), ...\n",
       "99    [[tensor(-0.2129, grad_fn=<UnbindBackward0>), ...\n",
       "Name: text_lemmatized, Length: 100, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ð¡Ð¶Ð°Ñ‚Ð¸Ðµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "\n",
    "def gzip_embedding(text):\n",
    "    \"\"\"Compute the GZIP compression embedding for a given text.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text to compute the embedding for.\n",
    "\n",
    "    Returns:\n",
    "        int: The GZIP compression embedding for the text.\n",
    "    \"\"\"\n",
    "    compressed_text = gzip.compress(text.encode())\n",
    "    return len(compressed_text)\n",
    "\n",
    "df['text_gzip'] = df['text_lemmatized'].apply(lambda x: gzip_embedding(' '.join(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "text_classes = df['text_type']\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit and transform the text classes\n",
    "df['text_type'] = le.fit_transform(text_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_type</th>\n",
       "      <th>text</th>\n",
       "      <th>text_tokenize</th>\n",
       "      <th>text_no_stop_words</th>\n",
       "      <th>text_lemmatized</th>\n",
       "      <th>text_tfidf</th>\n",
       "      <th>text_gzip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>make sure alex knows his birthday is over in f...</td>\n",
       "      <td>[make, sure, alex, knows, his, birthday, is, o...</td>\n",
       "      <td>[make, sure, alex, knows, birthday, fifteen, m...</td>\n",
       "      <td>[make, sure, alex, know, birthday, fifteen, mi...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>a resume for john lavorato thanks vince i will...</td>\n",
       "      <td>[a, resume, for, john, lavorato, thanks, vince...</td>\n",
       "      <td>[resume, john, lavorato, thanks, vince, get, m...</td>\n",
       "      <td>[resume, john, lavorato, thanks, vince, get, m...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>plzz visit my website moviesgodml to get all m...</td>\n",
       "      <td>[plzz, visit, my, website, moviesgodml, to, ge...</td>\n",
       "      <td>[plzz, visit, website, moviesgodml, get, movie...</td>\n",
       "      <td>[plzz, visit, website, moviesgodml, get, movie...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>urgent your mobile number has been awarded wit...</td>\n",
       "      <td>[urgent, your, mobile, number, has, been, awar...</td>\n",
       "      <td>[urgent, mobile, number, awarded, prize, guara...</td>\n",
       "      <td>[urgent, mobile, number, award, prize, guarant...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>overview of hr associates analyst project per ...</td>\n",
       "      <td>[overview, of, hr, associates, analyst, projec...</td>\n",
       "      <td>[overview, hr, associates, analyst, project, p...</td>\n",
       "      <td>[overview, hr, associate, analyst, project, pe...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16273</th>\n",
       "      <td>1</td>\n",
       "      <td>if you are interested in binary options tradin...</td>\n",
       "      <td>[if, you, are, interested, in, binary, options...</td>\n",
       "      <td>[interested, binary, options, trading, may, co...</td>\n",
       "      <td>[interested, binary, option, trading, may, con...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16274</th>\n",
       "      <td>1</td>\n",
       "      <td>dirty pictureblyk on aircel thanks you for bei...</td>\n",
       "      <td>[dirty, pictureblyk, on, aircel, thanks, you, ...</td>\n",
       "      <td>[dirty, pictureblyk, aircel, thanks, valued, m...</td>\n",
       "      <td>[dirty, pictureblyk, aircel, thanks, value, me...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16275</th>\n",
       "      <td>0</td>\n",
       "      <td>or you could do this g on mon 1635465 sep 1635...</td>\n",
       "      <td>[or, you, could, do, this, g, on, mon, sep, da...</td>\n",
       "      <td>[could, g, mon, sep, david, rees, wrote, mon, ...</td>\n",
       "      <td>[could, g, mon, sep, david, rees, write, mon, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16276</th>\n",
       "      <td>0</td>\n",
       "      <td>insta reels par 80 à¤—à¤‚à¤¦ bhara pada hai ðŸ‘€ kuch b...</td>\n",
       "      <td>[insta, reels, par, bhara, pada, hai, kuch, bh...</td>\n",
       "      <td>[insta, reels, par, bhara, pada, hai, kuch, bh...</td>\n",
       "      <td>[insta, reel, par, bhara, pada, hai, kuch, bhi...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16277</th>\n",
       "      <td>0</td>\n",
       "      <td>alex s paper comments 1 in the sentence betwee...</td>\n",
       "      <td>[alex, s, paper, comments, in, the, sentence, ...</td>\n",
       "      <td>[alex, paper, comments, sentence, eqn, eqn, th...</td>\n",
       "      <td>[alex, paper, comment, sentence, eqn, eqn, thi...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16278 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       text_type                                               text  \\\n",
       "0              0  make sure alex knows his birthday is over in f...   \n",
       "1              0  a resume for john lavorato thanks vince i will...   \n",
       "2              1  plzz visit my website moviesgodml to get all m...   \n",
       "3              1  urgent your mobile number has been awarded wit...   \n",
       "4              0  overview of hr associates analyst project per ...   \n",
       "...          ...                                                ...   \n",
       "16273          1  if you are interested in binary options tradin...   \n",
       "16274          1  dirty pictureblyk on aircel thanks you for bei...   \n",
       "16275          0  or you could do this g on mon 1635465 sep 1635...   \n",
       "16276          0  insta reels par 80 à¤—à¤‚à¤¦ bhara pada hai ðŸ‘€ kuch b...   \n",
       "16277          0  alex s paper comments 1 in the sentence betwee...   \n",
       "\n",
       "                                           text_tokenize  \\\n",
       "0      [make, sure, alex, knows, his, birthday, is, o...   \n",
       "1      [a, resume, for, john, lavorato, thanks, vince...   \n",
       "2      [plzz, visit, my, website, moviesgodml, to, ge...   \n",
       "3      [urgent, your, mobile, number, has, been, awar...   \n",
       "4      [overview, of, hr, associates, analyst, projec...   \n",
       "...                                                  ...   \n",
       "16273  [if, you, are, interested, in, binary, options...   \n",
       "16274  [dirty, pictureblyk, on, aircel, thanks, you, ...   \n",
       "16275  [or, you, could, do, this, g, on, mon, sep, da...   \n",
       "16276  [insta, reels, par, bhara, pada, hai, kuch, bh...   \n",
       "16277  [alex, s, paper, comments, in, the, sentence, ...   \n",
       "\n",
       "                                      text_no_stop_words  \\\n",
       "0      [make, sure, alex, knows, birthday, fifteen, m...   \n",
       "1      [resume, john, lavorato, thanks, vince, get, m...   \n",
       "2      [plzz, visit, website, moviesgodml, get, movie...   \n",
       "3      [urgent, mobile, number, awarded, prize, guara...   \n",
       "4      [overview, hr, associates, analyst, project, p...   \n",
       "...                                                  ...   \n",
       "16273  [interested, binary, options, trading, may, co...   \n",
       "16274  [dirty, pictureblyk, aircel, thanks, valued, m...   \n",
       "16275  [could, g, mon, sep, david, rees, wrote, mon, ...   \n",
       "16276  [insta, reels, par, bhara, pada, hai, kuch, bh...   \n",
       "16277  [alex, paper, comments, sentence, eqn, eqn, th...   \n",
       "\n",
       "                                         text_lemmatized  text_tfidf  \\\n",
       "0      [make, sure, alex, know, birthday, fifteen, mi...         0.0   \n",
       "1      [resume, john, lavorato, thanks, vince, get, m...         0.0   \n",
       "2      [plzz, visit, website, moviesgodml, get, movie...         0.0   \n",
       "3      [urgent, mobile, number, award, prize, guarant...         0.0   \n",
       "4      [overview, hr, associate, analyst, project, pe...         0.0   \n",
       "...                                                  ...         ...   \n",
       "16273  [interested, binary, option, trading, may, con...         0.0   \n",
       "16274  [dirty, pictureblyk, aircel, thanks, value, me...         0.0   \n",
       "16275  [could, g, mon, sep, david, rees, write, mon, ...         0.0   \n",
       "16276  [insta, reel, par, bhara, pada, hai, kuch, bhi...         0.0   \n",
       "16277  [alex, paper, comment, sentence, eqn, eqn, thi...         0.0   \n",
       "\n",
       "       text_gzip  \n",
       "0             75  \n",
       "1            213  \n",
       "2             86  \n",
       "3             76  \n",
       "4            304  \n",
       "...          ...  \n",
       "16273         76  \n",
       "16274        228  \n",
       "16275        253  \n",
       "16276         85  \n",
       "16277        268  \n",
       "\n",
       "[16278 rows x 7 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        1\n",
       "3        1\n",
       "4        0\n",
       "        ..\n",
       "16273    1\n",
       "16274    1\n",
       "16275    0\n",
       "16276    0\n",
       "16277    0\n",
       "Name: text_type, Length: 16278, dtype: int32"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df['text_tfidf']\n",
    "y = df['text_type']\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7066953316953317\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Assume X is your TF-IDF embeddings and y is your text_type column\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "X_train= X_train.reshape(-1, 1)\n",
    "X_test =  X_test.reshape(-1, 1)\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred_tfidf = log_reg.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7023955773955773\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gzip\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Extract features and labels from the DataFrame\n",
    "X = df['text_gzip'].values\n",
    "y = df['text_type'].values\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Train the logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train.reshape(-1, 1), y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_gzip = model.predict(X_test.reshape(-1, 1))\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred_gzip)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Embeddings Metrics:\n",
      "Accuracy: 0.7066953316953317\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83      2300\n",
      "           1       1.00      0.00      0.00       956\n",
      "\n",
      "    accuracy                           0.71      3256\n",
      "   macro avg       0.85      0.50      0.42      3256\n",
      "weighted avg       0.79      0.71      0.59      3256\n",
      "\n",
      "Confusion Matrix:\n",
      " [[2300    0]\n",
      " [ 955    1]]\n",
      "\n",
      "Gzip Embeddings Metrics:\n",
      "Accuracy: 0.7063882063882064\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83      2300\n",
      "           1       0.00      0.00      0.00       956\n",
      "\n",
      "    accuracy                           0.71      3256\n",
      "   macro avg       0.35      0.50      0.41      3256\n",
      "weighted avg       0.50      0.71      0.58      3256\n",
      "\n",
      "Confusion Matrix:\n",
      " [[2300    0]\n",
      " [ 956    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ataka\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\ataka\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\ataka\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gzip\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "tfidf_accuracy = accuracy_score(y_test, y_pred_tfidf)\n",
    "tfidf_class_report = classification_report(y_test, y_pred_tfidf)\n",
    "tfidf_confusion_matrix = confusion_matrix(y_test, y_pred_tfidf)\n",
    "\n",
    "# Evaluate the metrics using gzip embeddings\n",
    "gzip_accuracy = accuracy_score(y_test, y_pred_gzip)\n",
    "gzip_class_report = classification_report(y_test, y_pred_gzip)\n",
    "gzip_confusion_matrix = confusion_matrix(y_test, y_pred_gzip)\n",
    "\n",
    "# Print the metrics for comparison\n",
    "print(\"TF-IDF Embeddings Metrics:\")\n",
    "print(\"Accuracy:\", tfidf_accuracy)\n",
    "print(\"Classification Report:\\n\", tfidf_class_report)\n",
    "print(\"Confusion Matrix:\\n\", tfidf_confusion_matrix)\n",
    "\n",
    "print(\"\\nGzip Embeddings Metrics:\")\n",
    "print(\"Accuracy:\", gzip_accuracy)\n",
    "print(\"Classification Report:\\n\", gzip_class_report)\n",
    "print(\"Confusion Matrix:\\n\", gzip_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test_spam.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>j jim whitehead ejw cse ucsc edu writes j you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>original message from bitbitch magnesium net p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>java for managers vince durasoft who just taug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>there is a youtuber name saiman says</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>underpriced issue with high return on equity t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4065</th>\n",
       "      <td>husband to wifetum meri zindagi hoorwifeor kya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4066</th>\n",
       "      <td>baylor enron case study cindy yes i shall co a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4067</th>\n",
       "      <td>boring as compared to tp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4068</th>\n",
       "      <td>hellogorgeous hows u my fone was on charge lst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4069</th>\n",
       "      <td>energy conference mark we are really swamped a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4070 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "0     j jim whitehead ejw cse ucsc edu writes j you ...\n",
       "1     original message from bitbitch magnesium net p...\n",
       "2     java for managers vince durasoft who just taug...\n",
       "3                  there is a youtuber name saiman says\n",
       "4     underpriced issue with high return on equity t...\n",
       "...                                                 ...\n",
       "4065  husband to wifetum meri zindagi hoorwifeor kya...\n",
       "4066  baylor enron case study cindy yes i shall co a...\n",
       "4067                           boring as compared to tp\n",
       "4068  hellogorgeous hows u my fone was on charge lst...\n",
       "4069  energy conference mark we are really swamped a...\n",
       "\n",
       "[4070 rows x 1 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepropcess_data(df):\n",
    "    '''\n",
    "    '''\n",
    "    # 1) LowerCase\n",
    "    df['text'] = df['text'].str.lower()\n",
    "\n",
    "    # 2) Tokenize\n",
    "    def tokenize(text):\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        return [w for w in tokens if w.isalpha()]\n",
    "    df['text_tokenize'] = df['text'].apply(tokenize)\n",
    "\n",
    "    # 3) Stop-words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    df['text_no_stop_words'] = df['text_tokenize'].apply(lambda x: [word for word in x if word.lower() not in stop_words])\n",
    "\n",
    "    # 4) Lem\n",
    "    def lemmatize_word(word):\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        pos_tag = get_wordnet_pos(word)\n",
    "        lemma = lemmatizer.lemmatize(word, pos=pos_tag)\n",
    "        return lemma\n",
    "    def get_wordnet_pos(word):\n",
    "        tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "        tag_dict = {\"J\": wordnet.ADJ,\n",
    "                    \"N\": wordnet.NOUN,\n",
    "                    \"V\": wordnet.VERB,\n",
    "                    \"R\": wordnet.ADV}\n",
    "        return tag_dict.get(tag, wordnet.NOUN)\n",
    "    df['text_lemmatized'] = df['text_no_stop_words'].apply(lambda x: [lemmatize_word(word) for word in x])\n",
    "\n",
    "    return df\n",
    "\n",
    "df_test_preprocess = prepropcess_data(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_tokenize</th>\n",
       "      <th>text_no_stop_words</th>\n",
       "      <th>text_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>j jim whitehead ejw cse ucsc edu writes j you ...</td>\n",
       "      <td>[j, jim, whitehead, ejw, cse, ucsc, edu, write...</td>\n",
       "      <td>[j, jim, whitehead, ejw, cse, ucsc, edu, write...</td>\n",
       "      <td>[j, jim, whitehead, ejw, cse, ucsc, edu, write...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>original message from bitbitch magnesium net p...</td>\n",
       "      <td>[original, message, from, bitbitch, magnesium,...</td>\n",
       "      <td>[original, message, bitbitch, magnesium, net, ...</td>\n",
       "      <td>[original, message, bitbitch, magnesium, net, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>java for managers vince durasoft who just taug...</td>\n",
       "      <td>[java, for, managers, vince, durasoft, who, ju...</td>\n",
       "      <td>[java, managers, vince, durasoft, taught, java...</td>\n",
       "      <td>[java, manager, vince, durasoft, taught, java,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>there is a youtuber name saiman says</td>\n",
       "      <td>[there, is, a, youtuber, name, saiman, says]</td>\n",
       "      <td>[youtuber, name, saiman, says]</td>\n",
       "      <td>[youtuber, name, saiman, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>underpriced issue with high return on equity t...</td>\n",
       "      <td>[underpriced, issue, with, high, return, on, e...</td>\n",
       "      <td>[underpriced, issue, high, return, equity, oil...</td>\n",
       "      <td>[underpriced, issue, high, return, equity, oil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4065</th>\n",
       "      <td>husband to wifetum meri zindagi hoorwifeor kya...</td>\n",
       "      <td>[husband, to, wifetum, meri, zindagi, hoorwife...</td>\n",
       "      <td>[husband, wifetum, meri, zindagi, hoorwifeor, ...</td>\n",
       "      <td>[husband, wifetum, meri, zindagi, hoorwifeor, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4066</th>\n",
       "      <td>baylor enron case study cindy yes i shall co a...</td>\n",
       "      <td>[baylor, enron, case, study, cindy, yes, i, sh...</td>\n",
       "      <td>[baylor, enron, case, study, cindy, yes, shall...</td>\n",
       "      <td>[baylor, enron, case, study, cindy, yes, shall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4067</th>\n",
       "      <td>boring as compared to tp</td>\n",
       "      <td>[boring, as, compared, to, tp]</td>\n",
       "      <td>[boring, compared, tp]</td>\n",
       "      <td>[boring, compare, tp]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4068</th>\n",
       "      <td>hellogorgeous hows u my fone was on charge lst...</td>\n",
       "      <td>[hellogorgeous, hows, u, my, fone, was, on, ch...</td>\n",
       "      <td>[hellogorgeous, hows, u, fone, charge, lst, ni...</td>\n",
       "      <td>[hellogorgeous, hows, u, fone, charge, lst, ni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4069</th>\n",
       "      <td>energy conference mark we are really swamped a...</td>\n",
       "      <td>[energy, conference, mark, we, are, really, sw...</td>\n",
       "      <td>[energy, conference, mark, really, swamped, wo...</td>\n",
       "      <td>[energy, conference, mark, really, swamp, woul...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4070 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "0     j jim whitehead ejw cse ucsc edu writes j you ...   \n",
       "1     original message from bitbitch magnesium net p...   \n",
       "2     java for managers vince durasoft who just taug...   \n",
       "3                  there is a youtuber name saiman says   \n",
       "4     underpriced issue with high return on equity t...   \n",
       "...                                                 ...   \n",
       "4065  husband to wifetum meri zindagi hoorwifeor kya...   \n",
       "4066  baylor enron case study cindy yes i shall co a...   \n",
       "4067                           boring as compared to tp   \n",
       "4068  hellogorgeous hows u my fone was on charge lst...   \n",
       "4069  energy conference mark we are really swamped a...   \n",
       "\n",
       "                                          text_tokenize  \\\n",
       "0     [j, jim, whitehead, ejw, cse, ucsc, edu, write...   \n",
       "1     [original, message, from, bitbitch, magnesium,...   \n",
       "2     [java, for, managers, vince, durasoft, who, ju...   \n",
       "3          [there, is, a, youtuber, name, saiman, says]   \n",
       "4     [underpriced, issue, with, high, return, on, e...   \n",
       "...                                                 ...   \n",
       "4065  [husband, to, wifetum, meri, zindagi, hoorwife...   \n",
       "4066  [baylor, enron, case, study, cindy, yes, i, sh...   \n",
       "4067                     [boring, as, compared, to, tp]   \n",
       "4068  [hellogorgeous, hows, u, my, fone, was, on, ch...   \n",
       "4069  [energy, conference, mark, we, are, really, sw...   \n",
       "\n",
       "                                     text_no_stop_words  \\\n",
       "0     [j, jim, whitehead, ejw, cse, ucsc, edu, write...   \n",
       "1     [original, message, bitbitch, magnesium, net, ...   \n",
       "2     [java, managers, vince, durasoft, taught, java...   \n",
       "3                        [youtuber, name, saiman, says]   \n",
       "4     [underpriced, issue, high, return, equity, oil...   \n",
       "...                                                 ...   \n",
       "4065  [husband, wifetum, meri, zindagi, hoorwifeor, ...   \n",
       "4066  [baylor, enron, case, study, cindy, yes, shall...   \n",
       "4067                             [boring, compared, tp]   \n",
       "4068  [hellogorgeous, hows, u, fone, charge, lst, ni...   \n",
       "4069  [energy, conference, mark, really, swamped, wo...   \n",
       "\n",
       "                                        text_lemmatized  \n",
       "0     [j, jim, whitehead, ejw, cse, ucsc, edu, write...  \n",
       "1     [original, message, bitbitch, magnesium, net, ...  \n",
       "2     [java, manager, vince, durasoft, taught, java,...  \n",
       "3                         [youtuber, name, saiman, say]  \n",
       "4     [underpriced, issue, high, return, equity, oil...  \n",
       "...                                                 ...  \n",
       "4065  [husband, wifetum, meri, zindagi, hoorwifeor, ...  \n",
       "4066  [baylor, enron, case, study, cindy, yes, shall...  \n",
       "4067                              [boring, compare, tp]  \n",
       "4068  [hellogorgeous, hows, u, fone, charge, lst, ni...  \n",
       "4069  [energy, conference, mark, really, swamp, woul...  \n",
       "\n",
       "[4070 rows x 4 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_tfidf(df):\n",
    "\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    df['text_tfidf'] = df['text_lemmatized'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "    tf_idf_emb = vectorizer.fit_transform(df['text_tfidf'])\n",
    "    df['text_tfidf'] = tf_idf_emb.toarray()\n",
    "\n",
    "    return df\n",
    "\n",
    "df_test_emb_tfidf = get_embeddings_tfidf(df_test_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_tokenize</th>\n",
       "      <th>text_no_stop_words</th>\n",
       "      <th>text_lemmatized</th>\n",
       "      <th>text_tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>j jim whitehead ejw cse ucsc edu writes j you ...</td>\n",
       "      <td>[j, jim, whitehead, ejw, cse, ucsc, edu, write...</td>\n",
       "      <td>[j, jim, whitehead, ejw, cse, ucsc, edu, write...</td>\n",
       "      <td>[j, jim, whitehead, ejw, cse, ucsc, edu, write...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>original message from bitbitch magnesium net p...</td>\n",
       "      <td>[original, message, from, bitbitch, magnesium,...</td>\n",
       "      <td>[original, message, bitbitch, magnesium, net, ...</td>\n",
       "      <td>[original, message, bitbitch, magnesium, net, ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>java for managers vince durasoft who just taug...</td>\n",
       "      <td>[java, for, managers, vince, durasoft, who, ju...</td>\n",
       "      <td>[java, managers, vince, durasoft, taught, java...</td>\n",
       "      <td>[java, manager, vince, durasoft, taught, java,...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>there is a youtuber name saiman says</td>\n",
       "      <td>[there, is, a, youtuber, name, saiman, says]</td>\n",
       "      <td>[youtuber, name, saiman, says]</td>\n",
       "      <td>[youtuber, name, saiman, say]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>underpriced issue with high return on equity t...</td>\n",
       "      <td>[underpriced, issue, with, high, return, on, e...</td>\n",
       "      <td>[underpriced, issue, high, return, equity, oil...</td>\n",
       "      <td>[underpriced, issue, high, return, equity, oil...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4065</th>\n",
       "      <td>husband to wifetum meri zindagi hoorwifeor kya...</td>\n",
       "      <td>[husband, to, wifetum, meri, zindagi, hoorwife...</td>\n",
       "      <td>[husband, wifetum, meri, zindagi, hoorwifeor, ...</td>\n",
       "      <td>[husband, wifetum, meri, zindagi, hoorwifeor, ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4066</th>\n",
       "      <td>baylor enron case study cindy yes i shall co a...</td>\n",
       "      <td>[baylor, enron, case, study, cindy, yes, i, sh...</td>\n",
       "      <td>[baylor, enron, case, study, cindy, yes, shall...</td>\n",
       "      <td>[baylor, enron, case, study, cindy, yes, shall...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4067</th>\n",
       "      <td>boring as compared to tp</td>\n",
       "      <td>[boring, as, compared, to, tp]</td>\n",
       "      <td>[boring, compared, tp]</td>\n",
       "      <td>[boring, compare, tp]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4068</th>\n",
       "      <td>hellogorgeous hows u my fone was on charge lst...</td>\n",
       "      <td>[hellogorgeous, hows, u, my, fone, was, on, ch...</td>\n",
       "      <td>[hellogorgeous, hows, u, fone, charge, lst, ni...</td>\n",
       "      <td>[hellogorgeous, hows, u, fone, charge, lst, ni...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4069</th>\n",
       "      <td>energy conference mark we are really swamped a...</td>\n",
       "      <td>[energy, conference, mark, we, are, really, sw...</td>\n",
       "      <td>[energy, conference, mark, really, swamped, wo...</td>\n",
       "      <td>[energy, conference, mark, really, swamp, woul...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4070 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "0     j jim whitehead ejw cse ucsc edu writes j you ...   \n",
       "1     original message from bitbitch magnesium net p...   \n",
       "2     java for managers vince durasoft who just taug...   \n",
       "3                  there is a youtuber name saiman says   \n",
       "4     underpriced issue with high return on equity t...   \n",
       "...                                                 ...   \n",
       "4065  husband to wifetum meri zindagi hoorwifeor kya...   \n",
       "4066  baylor enron case study cindy yes i shall co a...   \n",
       "4067                           boring as compared to tp   \n",
       "4068  hellogorgeous hows u my fone was on charge lst...   \n",
       "4069  energy conference mark we are really swamped a...   \n",
       "\n",
       "                                          text_tokenize  \\\n",
       "0     [j, jim, whitehead, ejw, cse, ucsc, edu, write...   \n",
       "1     [original, message, from, bitbitch, magnesium,...   \n",
       "2     [java, for, managers, vince, durasoft, who, ju...   \n",
       "3          [there, is, a, youtuber, name, saiman, says]   \n",
       "4     [underpriced, issue, with, high, return, on, e...   \n",
       "...                                                 ...   \n",
       "4065  [husband, to, wifetum, meri, zindagi, hoorwife...   \n",
       "4066  [baylor, enron, case, study, cindy, yes, i, sh...   \n",
       "4067                     [boring, as, compared, to, tp]   \n",
       "4068  [hellogorgeous, hows, u, my, fone, was, on, ch...   \n",
       "4069  [energy, conference, mark, we, are, really, sw...   \n",
       "\n",
       "                                     text_no_stop_words  \\\n",
       "0     [j, jim, whitehead, ejw, cse, ucsc, edu, write...   \n",
       "1     [original, message, bitbitch, magnesium, net, ...   \n",
       "2     [java, managers, vince, durasoft, taught, java...   \n",
       "3                        [youtuber, name, saiman, says]   \n",
       "4     [underpriced, issue, high, return, equity, oil...   \n",
       "...                                                 ...   \n",
       "4065  [husband, wifetum, meri, zindagi, hoorwifeor, ...   \n",
       "4066  [baylor, enron, case, study, cindy, yes, shall...   \n",
       "4067                             [boring, compared, tp]   \n",
       "4068  [hellogorgeous, hows, u, fone, charge, lst, ni...   \n",
       "4069  [energy, conference, mark, really, swamped, wo...   \n",
       "\n",
       "                                        text_lemmatized  text_tfidf  \n",
       "0     [j, jim, whitehead, ejw, cse, ucsc, edu, write...         0.0  \n",
       "1     [original, message, bitbitch, magnesium, net, ...         0.0  \n",
       "2     [java, manager, vince, durasoft, taught, java,...         0.0  \n",
       "3                         [youtuber, name, saiman, say]         0.0  \n",
       "4     [underpriced, issue, high, return, equity, oil...         0.0  \n",
       "...                                                 ...         ...  \n",
       "4065  [husband, wifetum, meri, zindagi, hoorwifeor, ...         0.0  \n",
       "4066  [baylor, enron, case, study, cindy, yes, shall...         0.0  \n",
       "4067                              [boring, compare, tp]         0.0  \n",
       "4068  [hellogorgeous, hows, u, fone, charge, lst, ni...         0.0  \n",
       "4069  [energy, conference, mark, really, swamp, woul...         0.0  \n",
       "\n",
       "[4070 rows x 5 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_emb_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test_emb_tfidf['text_tfidf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_test_pred_tfidf = log_reg.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_tfidf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
