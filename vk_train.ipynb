{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ataka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ataka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\ataka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from utils import prepropcess_data, get_embeddings_tfidf, get_embeddings_gzip\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_spam.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preproc = prepropcess_data(df)\n",
    "# df_emb = get_embeddings_tfidf(df_preproc)\n",
    "# df_emb = get_embeddings_gzip(df_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_type</th>\n",
       "      <th>text</th>\n",
       "      <th>text_tokenize</th>\n",
       "      <th>text_no_stop_words</th>\n",
       "      <th>text_lemmatized</th>\n",
       "      <th>final_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>make sure alex knows his birthday is over in f...</td>\n",
       "      <td>[make, sure, alex, knows, his, birthday, is, o...</td>\n",
       "      <td>[make, sure, alex, knows, birthday, fifteen, m...</td>\n",
       "      <td>[make, sure, alex, know, birthday, fifteen, mi...</td>\n",
       "      <td>make sure alex know birthday fifteen minute fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>a resume for john lavorato thanks vince i will...</td>\n",
       "      <td>[a, resume, for, john, lavorato, thanks, vince...</td>\n",
       "      <td>[resume, john, lavorato, thanks, vince, get, m...</td>\n",
       "      <td>[resume, john, lavorato, thanks, vince, get, m...</td>\n",
       "      <td>resume john lavorato thanks vince get move rig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>plzz visit my website moviesgodml to get all m...</td>\n",
       "      <td>[plzz, visit, my, website, moviesgodml, to, ge...</td>\n",
       "      <td>[plzz, visit, website, moviesgodml, get, movie...</td>\n",
       "      <td>[plzz, visit, website, moviesgodml, get, movie...</td>\n",
       "      <td>plzz visit website moviesgodml get movie free ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>urgent your mobile number has been awarded wit...</td>\n",
       "      <td>[urgent, your, mobile, number, has, been, awar...</td>\n",
       "      <td>[urgent, mobile, number, awarded, prize, guara...</td>\n",
       "      <td>[urgent, mobile, number, award, prize, guarant...</td>\n",
       "      <td>urgent mobile number award prize guaranteed ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>overview of hr associates analyst project per ...</td>\n",
       "      <td>[overview, of, hr, associates, analyst, projec...</td>\n",
       "      <td>[overview, hr, associates, analyst, project, p...</td>\n",
       "      <td>[overview, hr, associate, analyst, project, pe...</td>\n",
       "      <td>overview hr associate analyst project per davi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16273</th>\n",
       "      <td>1</td>\n",
       "      <td>if you are interested in binary options tradin...</td>\n",
       "      <td>[if, you, are, interested, in, binary, options...</td>\n",
       "      <td>[interested, binary, options, trading, may, co...</td>\n",
       "      <td>[interested, binary, option, trading, may, con...</td>\n",
       "      <td>interested binary option trading may continue ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16274</th>\n",
       "      <td>1</td>\n",
       "      <td>dirty pictureblyk on aircel thanks you for bei...</td>\n",
       "      <td>[dirty, pictureblyk, on, aircel, thanks, you, ...</td>\n",
       "      <td>[dirty, pictureblyk, aircel, thanks, valued, m...</td>\n",
       "      <td>[dirty, pictureblyk, aircel, thanks, value, me...</td>\n",
       "      <td>dirty pictureblyk aircel thanks value member h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16275</th>\n",
       "      <td>0</td>\n",
       "      <td>or you could do this g on mon 1635465 sep 1635...</td>\n",
       "      <td>[or, you, could, do, this, g, on, mon, sep, da...</td>\n",
       "      <td>[could, g, mon, sep, david, rees, wrote, mon, ...</td>\n",
       "      <td>[could, g, mon, sep, david, rees, write, mon, ...</td>\n",
       "      <td>could g mon sep david rees write mon sep rob w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16276</th>\n",
       "      <td>0</td>\n",
       "      <td>insta reels par 80 ‡§ó‡§Ç‡§¶ bhara pada hai üëÄ kuch b...</td>\n",
       "      <td>[insta, reels, par, bhara, pada, hai, kuch, bh...</td>\n",
       "      <td>[insta, reels, par, bhara, pada, hai, kuch, bh...</td>\n",
       "      <td>[insta, reel, par, bhara, pada, hai, kuch, bhi...</td>\n",
       "      <td>insta reel par bhara pada hai kuch bhi dalte c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16277</th>\n",
       "      <td>0</td>\n",
       "      <td>alex s paper comments 1 in the sentence betwee...</td>\n",
       "      <td>[alex, s, paper, comments, in, the, sentence, ...</td>\n",
       "      <td>[alex, paper, comments, sentence, eqn, eqn, th...</td>\n",
       "      <td>[alex, paper, comment, sentence, eqn, eqn, thi...</td>\n",
       "      <td>alex paper comment sentence eqn eqn think annu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16278 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       text_type                                               text  \\\n",
       "0              0  make sure alex knows his birthday is over in f...   \n",
       "1              0  a resume for john lavorato thanks vince i will...   \n",
       "2              1  plzz visit my website moviesgodml to get all m...   \n",
       "3              1  urgent your mobile number has been awarded wit...   \n",
       "4              0  overview of hr associates analyst project per ...   \n",
       "...          ...                                                ...   \n",
       "16273          1  if you are interested in binary options tradin...   \n",
       "16274          1  dirty pictureblyk on aircel thanks you for bei...   \n",
       "16275          0  or you could do this g on mon 1635465 sep 1635...   \n",
       "16276          0  insta reels par 80 ‡§ó‡§Ç‡§¶ bhara pada hai üëÄ kuch b...   \n",
       "16277          0  alex s paper comments 1 in the sentence betwee...   \n",
       "\n",
       "                                           text_tokenize  \\\n",
       "0      [make, sure, alex, knows, his, birthday, is, o...   \n",
       "1      [a, resume, for, john, lavorato, thanks, vince...   \n",
       "2      [plzz, visit, my, website, moviesgodml, to, ge...   \n",
       "3      [urgent, your, mobile, number, has, been, awar...   \n",
       "4      [overview, of, hr, associates, analyst, projec...   \n",
       "...                                                  ...   \n",
       "16273  [if, you, are, interested, in, binary, options...   \n",
       "16274  [dirty, pictureblyk, on, aircel, thanks, you, ...   \n",
       "16275  [or, you, could, do, this, g, on, mon, sep, da...   \n",
       "16276  [insta, reels, par, bhara, pada, hai, kuch, bh...   \n",
       "16277  [alex, s, paper, comments, in, the, sentence, ...   \n",
       "\n",
       "                                      text_no_stop_words  \\\n",
       "0      [make, sure, alex, knows, birthday, fifteen, m...   \n",
       "1      [resume, john, lavorato, thanks, vince, get, m...   \n",
       "2      [plzz, visit, website, moviesgodml, get, movie...   \n",
       "3      [urgent, mobile, number, awarded, prize, guara...   \n",
       "4      [overview, hr, associates, analyst, project, p...   \n",
       "...                                                  ...   \n",
       "16273  [interested, binary, options, trading, may, co...   \n",
       "16274  [dirty, pictureblyk, aircel, thanks, valued, m...   \n",
       "16275  [could, g, mon, sep, david, rees, wrote, mon, ...   \n",
       "16276  [insta, reels, par, bhara, pada, hai, kuch, bh...   \n",
       "16277  [alex, paper, comments, sentence, eqn, eqn, th...   \n",
       "\n",
       "                                         text_lemmatized  \\\n",
       "0      [make, sure, alex, know, birthday, fifteen, mi...   \n",
       "1      [resume, john, lavorato, thanks, vince, get, m...   \n",
       "2      [plzz, visit, website, moviesgodml, get, movie...   \n",
       "3      [urgent, mobile, number, award, prize, guarant...   \n",
       "4      [overview, hr, associate, analyst, project, pe...   \n",
       "...                                                  ...   \n",
       "16273  [interested, binary, option, trading, may, con...   \n",
       "16274  [dirty, pictureblyk, aircel, thanks, value, me...   \n",
       "16275  [could, g, mon, sep, david, rees, write, mon, ...   \n",
       "16276  [insta, reel, par, bhara, pada, hai, kuch, bhi...   \n",
       "16277  [alex, paper, comment, sentence, eqn, eqn, thi...   \n",
       "\n",
       "                                              final_text  \n",
       "0      make sure alex know birthday fifteen minute fa...  \n",
       "1      resume john lavorato thanks vince get move rig...  \n",
       "2      plzz visit website moviesgodml get movie free ...  \n",
       "3      urgent mobile number award prize guaranteed ca...  \n",
       "4      overview hr associate analyst project per davi...  \n",
       "...                                                  ...  \n",
       "16273  interested binary option trading may continue ...  \n",
       "16274  dirty pictureblyk aircel thanks value member h...  \n",
       "16275  could g mon sep david rees write mon sep rob w...  \n",
       "16276  insta reel par bhara pada hai kuch bhi dalte c...  \n",
       "16277  alex paper comment sentence eqn eqn think annu...  \n",
       "\n",
       "[16278 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_tfidf = df_preproc['text_tfidf'].values\n",
    "# y_tfidf = df_preproc['text_type'].values\n",
    "\n",
    "\n",
    "# X_gzip = df_preproc['text_gzip'].values\n",
    "# y_gzip = df_preproc['text_type'].values\n",
    "\n",
    "# X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(X_tfidf, y_tfidf, test_size=0.2)\n",
    "# X_train_gzip, X_test_gzip, y_train_gzip, y_test_gzip = train_test_split(X_gzip, y_gzip, test_size=0.2)\n",
    "\n",
    "X_train = df_preproc['final_text'].values\n",
    "y_train = df_preproc['text_type'].values\n",
    "\n",
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(X_train, y_train, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –û–±—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏ –ø–æ–∏—Å–∫ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ü–æ–¥–±–æ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "\n",
    "svm = SVC()\n",
    "param_grid_svm = {\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (2, 2)],\n",
    "    'tfidf__max_df': [0.5, 0.75, 1.0],\n",
    "    'svm__C': [0.1, 1, 10, 100, 1000],\n",
    "    'svm__kernel': ['linear', 'rbf', 'poly'],\n",
    "    'svm__gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "lr = LogisticRegression()\n",
    "param_grid_lr = {\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (2, 2)],\n",
    "    'tfidf__max_df': [0.5, 0.75, 1.0],\n",
    "    'lr__C': [0.1, 1, 10, 100, 1000, 5000, 10000, 100000],\n",
    "    'lr__penalty': ['l1', 'l2', 'elasticnet']\n",
    "}\n",
    "\n",
    "nb = MultinomialNB()\n",
    "param_grid_nb = {\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (2, 2)],\n",
    "    'tfidf__max_df': [0.5, 0.75, 1.0],\n",
    "    'nb__alpha': [0.1, 1, 10],\n",
    "    'nb__fit_prior': [True, False]\n",
    "}\n",
    "\n",
    "pipeline_svm = Pipeline([\n",
    "    ('tfidf', tfidf),\n",
    "    ('svm', svm)\n",
    "])\n",
    "pipeline_lr = Pipeline([\n",
    "    ('tfidf', tfidf),\n",
    "    ('lr', lr)\n",
    "])\n",
    "pipeline_nb = Pipeline([\n",
    "('tfidf', tfidf),\n",
    "    ('nb', nb)\n",
    "])\n",
    "\n",
    "grid_search_svm = GridSearchCV(pipeline_svm, param_grid_svm, cv=5, scoring='f1_macro')\n",
    "grid_search_lr = GridSearchCV(pipeline_lr, param_grid_lr, cv=5, scoring='f1_macro')\n",
    "grid_search_nb = GridSearchCV(pipeline_nb, param_grid_nb, cv=5, scoring='f1_macro')\n",
    "\n",
    "random_search_svm = RandomizedSearchCV(pipeline_svm, param_grid_svm, cv=5, scoring='f1_macro', n_iter=10)\n",
    "random_search_lr = RandomizedSearchCV(pipeline_lr, param_grid_lr, cv=5, scoring='f1_macro', n_iter=10)\n",
    "random_search_nb = RandomizedSearchCV(pipeline_nb, param_grid_nb, cv=5, scoring='f1_macro', n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters for SVM model:\n",
      "{'svm__C': 100, 'svm__gamma': 'scale', 'svm__kernel': 'linear', 'tfidf__max_df': 0.5, 'tfidf__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "grid_search_svm.fit(X_train_tfidf[:1000], y_train_tfidf[:1000])\n",
    "\n",
    "# Print the best hyperparameters for the SVM model\n",
    "print(\"Best hyperparameters for SVM model:\")\n",
    "print(grid_search_svm.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best hyperparameters for SVM model:    \n",
    "{'svm__C': 10, 'svm__gamma': 'scale', 'svm__kernel': 'linear', 'tfidf__max_df': 0.5, 'tfidf__ngram_range': (1, 2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ataka\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "720 fits failed out of a total of 1080.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "360 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ataka\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\ataka\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\ataka\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\pipeline.py\", line 427, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\ataka\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\ataka\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\ataka\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "360 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ataka\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\ataka\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\ataka\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\pipeline.py\", line 427, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\ataka\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\ataka\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\ataka\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\ataka\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.41245472 0.41245472 0.41245472\n",
      " 0.41245472 0.41245472 0.41245472 0.41245472 0.41245472 0.41245472\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.6450783  0.54270072 0.41245472 0.6450783  0.54270072 0.41245472\n",
      " 0.6450783  0.54270072 0.41245472        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.8306867  0.82799632 0.5712269\n",
      " 0.8306867  0.82799632 0.5712269  0.8306867  0.82799632 0.5712269\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.8471589  0.84563004 0.59755088 0.8471589  0.84563004 0.59755088\n",
      " 0.8471589  0.84563004 0.59755088        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.85701304 0.85327071 0.62353597\n",
      " 0.85701304 0.85327071 0.62353597 0.85701304 0.85327071 0.62353597\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.85701304 0.85498308 0.63528644 0.85701304 0.85498308 0.63528644\n",
      " 0.85701304 0.85498308 0.63528644        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.85701304 0.85629648 0.63980335\n",
      " 0.85701304 0.85629648 0.63980335 0.85701304 0.85629648 0.63980335\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.86006849 0.86346914 0.67056121 0.86006849 0.86346914 0.67056121\n",
      " 0.86006849 0.86346914 0.67056121        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters for LR model:\n",
      "{'lr__C': 100000, 'lr__penalty': 'l2', 'tfidf__max_df': 0.5, 'tfidf__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "grid_search_lr.fit(X_train_tfidf[:1000], y_train_tfidf[:1000])\n",
    "\n",
    "# Print the best hyperparameters for the SVM model\n",
    "print(\"Best hyperparameters for LR model:\")\n",
    "print(grid_search_lr.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best hyperparameters for LR model:\n",
    "{'lr__C': 10, 'lr__penalty': 'l2', 'tfidf__max_df': 0.5, 'tfidf__ngram_range': (1, 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters for NB model:\n",
      "{'nb__alpha': 0.1, 'nb__fit_prior': False, 'tfidf__max_df': 0.5, 'tfidf__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "grid_search_nb.fit(X_train_tfidf[:5000], y_train_tfidf[:5000])\n",
    "\n",
    "# Print the best hyperparameters for the SVM model\n",
    "print(\"Best hyperparameters for NB model:\")\n",
    "print(grid_search_nb.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best hyperparameters for NB model:\n",
    "{'nb__alpha': 0.1, 'nb__fit_prior': False, 'tfidf__max_df': 0.5, 'tfidf__ngram_range': (1, 2)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –û–±—É—á–µ–Ω–∏–µ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer(max_df=0.5, ngram_range=(1, 2))),\n",
       "                (&#x27;svm&#x27;, SVC(C=100, kernel=&#x27;linear&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer(max_df=0.5, ngram_range=(1, 2))),\n",
       "                (&#x27;svm&#x27;, SVC(C=100, kernel=&#x27;linear&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_df=0.5, ngram_range=(1, 2))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=100, kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer(max_df=0.5, ngram_range=(1, 2))),\n",
       "                ('svm', SVC(C=100, kernel='linear'))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# {'svm__C': 10, 'svm__gamma': 'scale', 'svm__kernel': 'linear', 'tfidf__max_df': 0.5, 'tfidf__ngram_range': (1, 2)}\n",
    "tfidf = TfidfVectorizer(max_df=0.5, ngram_range=(1, 2))\n",
    "\n",
    "\n",
    "svm = SVC(C=100, gamma='scale', kernel='linear')\n",
    "\n",
    "pipeline_svm = Pipeline([\n",
    "    ('tfidf', tfidf),\n",
    "    ('svm', svm)\n",
    "])\n",
    "\n",
    "pipeline_svm.fit(X_train_tfidf, y_train_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search SVM model evaluation:\n",
      "Accuracy: 0.9404176904176904\n",
      "Precision: 0.8910191725529768\n",
      "Recall: 0.9112487100103199\n",
      "F1 score: 0.9010204081632653\n"
     ]
    }
   ],
   "source": [
    "y_pred_svm = pipeline_svm.predict(X_test_tfidf)\n",
    "print(\"Grid search SVM model evaluation:\") \n",
    "print(\"Accuracy:\", accuracy_score(y_test_tfidf, y_pred_svm))\n",
    "print(\"Precision:\", precision_score(y_test_tfidf, y_pred_svm))\n",
    "print(\"Recall:\", recall_score(y_test_tfidf, y_pred_svm))\n",
    "print(\"F1 score:\", f1_score(y_test_tfidf, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score: 0.9320\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc = roc_auc_score(y_test_tfidf, y_pred_svm)\n",
    "\n",
    "print(f\"ROC AUC score: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ataka\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer(max_df=0.5)),\n",
       "                (&#x27;lr&#x27;, LogisticRegression(C=100000))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer(max_df=0.5)),\n",
       "                (&#x27;lr&#x27;, LogisticRegression(C=100000))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_df=0.5)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=100000)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer(max_df=0.5)),\n",
       "                ('lr', LogisticRegression(C=100000))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# {'lr__C': 100000, 'lr__penalty': 'l2', 'tfidf__max_df': 0.5, 'tfidf__ngram_range': (1, 2)}\n",
    "tfidf = TfidfVectorizer(max_df=0.5, ngram_range=(1, 1))\n",
    "\n",
    "\n",
    "lr = LogisticRegression(C=100000, penalty='l2')\n",
    "\n",
    "pipeline_lr = Pipeline([\n",
    "    ('tfidf', tfidf),\n",
    "    ('lr', lr)\n",
    "])\n",
    "\n",
    "pipeline_lr.fit(X_train_tfidf, y_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search LR model evaluation:\n",
      "Accuracy: 0.9161547911547911\n",
      "Precision: 0.8486973947895792\n",
      "Recall: 0.8740970072239422\n",
      "F1 score: 0.8612099644128114\n"
     ]
    }
   ],
   "source": [
    "y_pred_lr = pipeline_lr.predict(X_test_tfidf)\n",
    "print(\"Grid search LR model evaluation:\") \n",
    "print(\"Accuracy:\", accuracy_score(y_test_tfidf, y_pred_lr))\n",
    "print(\"Precision:\", precision_score(y_test_tfidf, y_pred_lr))\n",
    "print(\"Recall:\", recall_score(y_test_tfidf, y_pred_lr))\n",
    "print(\"F1 score:\", f1_score(y_test_tfidf, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score: 0.9040\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc = roc_auc_score(y_test_tfidf, y_pred_lr)\n",
    "\n",
    "print(f\"ROC AUC score: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer(max_df=0.5, ngram_range=(1, 2))),\n",
       "                (&#x27;svm&#x27;, MultinomialNB(alpha=0.1, fit_prior=False))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer(max_df=0.5, ngram_range=(1, 2))),\n",
       "                (&#x27;svm&#x27;, MultinomialNB(alpha=0.1, fit_prior=False))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_df=0.5, ngram_range=(1, 2))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB(alpha=0.1, fit_prior=False)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer(max_df=0.5, ngram_range=(1, 2))),\n",
       "                ('svm', MultinomialNB(alpha=0.1, fit_prior=False))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# {'nb__alpha': 0.1, 'nb__fit_prior': False, 'tfidf__max_df': 0.5, 'tfidf__ngram_range': (1, 2)}\n",
    "tfidf = TfidfVectorizer(max_df=0.5, ngram_range=(1, 2))\n",
    "\n",
    "\n",
    "nb = MultinomialNB(alpha=0.1, fit_prior=False)\n",
    "\n",
    "pipeline_nb = Pipeline([\n",
    "    ('tfidf', tfidf),\n",
    "    ('svm', nb)\n",
    "])\n",
    "\n",
    "pipeline_nb.fit(X_train_tfidf, y_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search LR model evaluation:\n",
      "Accuracy: 0.9299754299754299\n",
      "Precision: 0.8614634146341463\n",
      "Recall: 0.9112487100103199\n",
      "F1 score: 0.8856569709127382\n"
     ]
    }
   ],
   "source": [
    "y_pred_nb = pipeline_nb.predict(X_test_tfidf)\n",
    "print(\"Grid search LR model evaluation:\") \n",
    "print(\"Accuracy:\", accuracy_score(y_test_tfidf, y_pred_nb))\n",
    "print(\"Precision:\", precision_score(y_test_tfidf, y_pred_nb))\n",
    "print(\"Recall:\", recall_score(y_test_tfidf, y_pred_nb))\n",
    "print(\"F1 score:\", f1_score(y_test_tfidf, y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score: 0.9246\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc = roc_auc_score(y_test_tfidf, y_pred_nb)\n",
    "\n",
    "print(f\"ROC AUC score: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test_spam.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>j jim whitehead ejw cse ucsc edu writes j you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>original message from bitbitch magnesium net p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>java for managers vince durasoft who just taug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>there is a youtuber name saiman says</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>underpriced issue with high return on equity t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4065</th>\n",
       "      <td>husband to wifetum meri zindagi hoorwifeor kya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4066</th>\n",
       "      <td>baylor enron case study cindy yes i shall co a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4067</th>\n",
       "      <td>boring as compared to tp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4068</th>\n",
       "      <td>hellogorgeous hows u my fone was on charge lst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4069</th>\n",
       "      <td>energy conference mark we are really swamped a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4070 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "0     j jim whitehead ejw cse ucsc edu writes j you ...\n",
       "1     original message from bitbitch magnesium net p...\n",
       "2     java for managers vince durasoft who just taug...\n",
       "3                  there is a youtuber name saiman says\n",
       "4     underpriced issue with high return on equity t...\n",
       "...                                                 ...\n",
       "4065  husband to wifetum meri zindagi hoorwifeor kya...\n",
       "4066  baylor enron case study cindy yes i shall co a...\n",
       "4067                           boring as compared to tp\n",
       "4068  hellogorgeous hows u my fone was on charge lst...\n",
       "4069  energy conference mark we are really swamped a...\n",
       "\n",
       "[4070 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_preproc = prepropcess_data(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_X_train = test_df_preproc['text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test_svm = pipeline_svm.predict(test_df_X_train)\n",
    "predict_test_lr = pipeline_lr.predict(test_df_X_train)\n",
    "predict_test_nb = pipeline_nb.predict(test_df_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df['score'] = predict_test_svm\n",
    "# result_df['LR'] = predict_test_lr\n",
    "# result_df['NB'] = predict_test_nb\n",
    "\n",
    "result_df['text'] = test_df['text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>j jim whitehead ejw cse ucsc edu writes j you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>original message from bitbitch magnesium net p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>java for managers vince durasoft who just taug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>there is a youtuber name saiman says</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>underpriced issue with high return on equity t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4065</th>\n",
       "      <td>0</td>\n",
       "      <td>husband to wifetum meri zindagi hoorwifeor kya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4066</th>\n",
       "      <td>0</td>\n",
       "      <td>baylor enron case study cindy yes i shall co a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4067</th>\n",
       "      <td>0</td>\n",
       "      <td>boring as compared to tp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4068</th>\n",
       "      <td>0</td>\n",
       "      <td>hellogorgeous hows u my fone was on charge lst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4069</th>\n",
       "      <td>0</td>\n",
       "      <td>energy conference mark we are really swamped a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4070 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      score                                               text\n",
       "0         0  j jim whitehead ejw cse ucsc edu writes j you ...\n",
       "1         0  original message from bitbitch magnesium net p...\n",
       "2         0  java for managers vince durasoft who just taug...\n",
       "3         0               there is a youtuber name saiman says\n",
       "4         1  underpriced issue with high return on equity t...\n",
       "...     ...                                                ...\n",
       "4065      0  husband to wifetum meri zindagi hoorwifeor kya...\n",
       "4066      0  baylor enron case study cindy yes i shall co a...\n",
       "4067      0                           boring as compared to tp\n",
       "4068      0  hellogorgeous hows u my fone was on charge lst...\n",
       "4069      0  energy conference mark we are really swamped a...\n",
       "\n",
       "[4070 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result_df['score'] = result_df['score'].map({0: 'ham', 1: 'spam'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>j jim whitehead ejw cse ucsc edu writes j you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>original message from bitbitch magnesium net p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>java for managers vince durasoft who just taug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>there is a youtuber name saiman says</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spam</td>\n",
       "      <td>underpriced issue with high return on equity t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4065</th>\n",
       "      <td>ham</td>\n",
       "      <td>husband to wifetum meri zindagi hoorwifeor kya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4066</th>\n",
       "      <td>ham</td>\n",
       "      <td>baylor enron case study cindy yes i shall co a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4067</th>\n",
       "      <td>ham</td>\n",
       "      <td>boring as compared to tp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4068</th>\n",
       "      <td>ham</td>\n",
       "      <td>hellogorgeous hows u my fone was on charge lst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4069</th>\n",
       "      <td>ham</td>\n",
       "      <td>energy conference mark we are really swamped a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4070 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     score                                               text\n",
       "0      ham  j jim whitehead ejw cse ucsc edu writes j you ...\n",
       "1      ham  original message from bitbitch magnesium net p...\n",
       "2      ham  java for managers vince durasoft who just taug...\n",
       "3      ham               there is a youtuber name saiman says\n",
       "4     spam  underpriced issue with high return on equity t...\n",
       "...    ...                                                ...\n",
       "4065   ham  husband to wifetum meri zindagi hoorwifeor kya...\n",
       "4066   ham  baylor enron case study cindy yes i shall co a...\n",
       "4067   ham                           boring as compared to tp\n",
       "4068   ham  hellogorgeous hows u my fone was on charge lst...\n",
       "4069   ham  energy conference mark we are really swamped a...\n",
       "\n",
       "[4070 rows x 2 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('result.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
